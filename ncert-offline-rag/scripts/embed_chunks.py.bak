"""
ncert-offline-rag/scripts/embed_chunks.py

Laptop-only: encode texts from a JSONL of chunks into embeddings.npy using SentenceTransformer.

Usage:
python ncert-offline-rag/scripts/embed_chunks.py \
  --input ncert-offline-rag/data_fixed/chapter_1.jsonl \
  --output ncert-offline-rag/data_fixed/embeddings.npy \
  --model all-mpnet-base-v2 \
  --batch 32
"""
"""
Patch: allow --text (single question) as alternative to --input JSON/JSONL.
If --text is provided the script will produce a single-file JSON containing:
  {"id":"q","embedding":[...]}
so it can be used as a quick q.json for retrieval/teacher RAG.
"""
from __future__ import annotations
from pathlib import Path
from typing import List, Dict
import json
import numpy as np
import argparse
import json
import sys
import os

# try to import sentence-transformers; if not present we'll show an instructive error
try:
    from sentence_transformers import SentenceTransformer
except Exception:
    SentenceTransformer = None


def load_texts(jsonl_path: Path) -> List[str]:
    texts: List[str] = []
    with jsonl_path.open("r", encoding="utf-8") as fh:
        for i, line in enumerate(fh, start=1):
            line = line.strip()
            if not line:
                continue
            obj = json.loads(line)
            if "text" not in obj:
                raise RuntimeError(f"Line {i}: missing 'text' field")
            texts.append(obj["text"])
    if not texts:
        raise RuntimeError("No texts found in JSONL")
    return texts


def encode_texts(texts: List[str], model_name: str, batch_size: int) -> np.ndarray:
    if SentenceTransformer is None:
        raise RuntimeError("sentence-transformers not installed. Run on laptop and install sentence-transformers")
    model = SentenceTransformer(model_name)
    embs = model.encode(texts, batch_size=batch_size, convert_to_numpy=True, show_progress_bar=True)
    if embs.dtype != np.float32:
        embs = embs.astype(np.float32)
    return embs


def main():
    parser = argparse.ArgumentParser(description="Embed chunks or single text (patched).")
    parser.add_argument("--input", help="input JSONL/JSON with texts to embed (original behaviour)")
    parser.add_argument("--text", help="single question/text to embed (shortcut, alternative to --input)")
    parser.add_argument("--output", required=True, help="output file (JSON or JSONL depending on mode)")
    parser.add_argument("--model", default="all-mpnet-base-v2", help="sentence-transformers model name")
    parser.add_argument("--batch", type=int, default=64, help="batch size for embedding when using --input")
    args = parser.parse_args()

    # If user provided --text, do quick single-embedding mode and exit
    if args.text:
        if SentenceTransformer is None:
            print("Missing dependency: sentence-transformers. Install in your venv:", file=sys.stderr)
            print(".venv/bin/python -m pip install sentence-transformers", file=sys.stderr)
            sys.exit(2)
        model = SentenceTransformer(args.model)
        # encode (normalize to unit vector to match typical retrieval expectations)
        vec = model.encode(args.text, normalize_embeddings=True).tolist()
        out_obj = {"id": "q", "embedding": vec}
        # write compact JSON (retrieve.py in this repo accepts simple embedding dicts)
        with open(args.output, "w", encoding="utf-8") as fh:
            json.dump(out_obj, fh, ensure_ascii=False)
        print(f"Wrote single-embedding to {args.output}")
        return

    # fall back to original behavior when --input is provided (embedding many chunks)
    if not args.input:
        parser.error("either --input (original) or --text (single) must be provided")
    if SentenceTransformer is None:
        print("Missing dependency: sentence-transformers. Install in your venv:", file=sys.stderr)
        print(".venv/bin/python -m pip install sentence-transformers", file=sys.stderr)
        sys.exit(2)
    model = SentenceTransformer(args.model)
    # Read lines (try JSONL)
    items = []
    with open(args.input, "r", encoding="utf-8") as fh:
        for line in fh:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except Exception:
                # try plain text line
                obj = {"id": None, "text": line}
            items.append(obj)
    texts = [o.get("text") or "" for o in items]
    embeddings = []
    for i in range(0, len(texts), args.batch):
        batch = texts[i : i + args.batch]
        embs = model.encode(batch, normalize_embeddings=True)
        # ensure list conversion for JSON
        for e in embs:
            embeddings.append(e.tolist() if hasattr(e, "tolist") else list(e))

    # Output as JSONL with id+embedding per line (or adjust to original expected format)
    out_dir = os.path.dirname(args.output) or "."
    os.makedirs(out_dir, exist_ok=True)
    with open(args.output, "w", encoding="utf-8") as fh:
        for obj, emb in zip(items, embeddings):
            out_line = {"id": obj.get("id") or obj.get("title") or None, "embedding": emb}
            fh.write(json.dumps(out_line, ensure_ascii=False) + "\n")
    print(f"Wrote {len(embeddings)} embeddings to {args.output}")


if __name__ == "__main__":
    main()